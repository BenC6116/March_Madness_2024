{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-25T12:18:07.532100Z",
     "iopub.status.busy": "2025-03-25T12:18:07.531802Z",
     "iopub.status.idle": "2025-03-25T12:18:10.350525Z",
     "shell.execute_reply": "2025-03-25T12:18:10.349245Z",
     "shell.execute_reply.started": "2025-03-25T12:18:07.532069Z"
    }
   },
   "source": [
    "# üèÄ Random Forest Model for March Madness Predictions\n",
    "\n",
    "This notebook implements and tunes a Random Forest model for predicting NCAA March Madness tournament outcomes. It includes feature selection, hyperparameter optimization with Optuna, and model evaluation using time-based cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:21:17.029315Z",
     "iopub.status.busy": "2025-05-04T14:21:17.028992Z",
     "iopub.status.idle": "2025-05-04T14:21:22.072149Z",
     "shell.execute_reply": "2025-05-04T14:21:22.071064Z",
     "shell.execute_reply.started": "2025-05-04T14:21:17.029285Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------- Imports and Configurations ---------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import brier_score_loss, log_loss\n",
    "import optuna\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Enable more readable display for DataFrames\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Adjust path based on environment\n",
    "if os.path.exists('/kaggle/input'):\n",
    "    sys.path.append('/kaggle/input/preprocessing-module')\n",
    "else:\n",
    "    sys.path.append('../../scripts')\n",
    "\n",
    "from pre_processing import build_model_pipeline, rolling_window_cv, generate_matchup_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T15:35:54.062413Z",
     "iopub.status.busy": "2025-05-04T15:35:54.062107Z",
     "iopub.status.idle": "2025-05-04T15:36:40.151737Z",
     "shell.execute_reply": "2025-05-04T15:36:40.150711Z",
     "shell.execute_reply.started": "2025-05-04T15:35:54.062394Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Dataset Summary:\n",
      "X shape: (8068, 10)\n",
      "y shape: (8068,)\n",
      "GameIDs shape: (8068,)\n",
      "\n",
      "Class distribution:\n",
      "Team1Wins\n",
      "1    4034\n",
      "0    4034\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Feature columns:\n",
      "['Season', 'SeedDiff', 'WinPctDiff', 'PointsForDiff', 'PointsAgainstDiff', 'AvgMarginDiff', 'Team1Games', 'Team2Games', 'Last14WinRateDiff', 'NeutralWinRateDiff']\n",
      "\n",
      "Sample features:\n",
      "   Season  SeedDiff  WinPctDiff  PointsForDiff  PointsAgainstDiff  AvgMarginDiff  Team1Games  Team2Games  Last14WinRateDiff  NeutralWinRateDiff\n",
      "0    1985         1   -0.030303             64                258      -6.830303          33          30           0.250000            0.033333\n",
      "1    1985         5   -0.059310            312                300      -0.110345          29          25           0.166667           -0.166667\n",
      "2    1985       -15    0.546616            138               -414      20.114943          27          29           0.200000            0.500000\n",
      "3    1985         1    0.062169             18                -37       2.177249          27          28          -0.166667            0.333333\n",
      "4    1985       -11    0.025926            457                411       1.077778          30          27           0.000000           -0.100000\n"
     ]
    }
   ],
   "source": [
    "# Load dataset using preprocessing pipeline\n",
    "X, y, game_ids = build_model_pipeline(model_type='rf')\n",
    "print(\"\\nRandom Forest Dataset Summary:\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"GameIDs shape: {game_ids.shape}\")\n",
    "print(\"\\nClass distribution:\")\n",
    "print(y.value_counts())\n",
    "print(\"\\nFeature columns:\")\n",
    "print(X.columns.tolist())\n",
    "print(\"\\nSample features:\")\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Definition and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:22:09.041771Z",
     "iopub.status.busy": "2025-05-04T14:22:09.041468Z",
     "iopub.status.idle": "2025-05-04T14:22:09.048091Z",
     "shell.execute_reply": "2025-05-04T14:22:09.047247Z",
     "shell.execute_reply.started": "2025-05-04T14:22:09.041750Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def rf_model_fn(X_train, y_train, X_test, y_test, test_season, model_params, sample_weight):\n",
    "    \"\"\"Random Forest model function for cross-validation.\n",
    "    \n",
    "    Scales features, trains a Random Forest model with provided parameters,\n",
    "    and returns evaluation metrics.\n",
    "    \"\"\"\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestClassifier(**model_params)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Generate predictions and calculate metrics\n",
    "    preds_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    brier_val = brier_score_loss(y_test, preds_proba)\n",
    "    logloss_val = log_loss(y_test, preds_proba)\n",
    "    preds_class = (preds_proba >= 0.5).astype(int)\n",
    "    accuracy_val = (preds_class == y_test).mean()\n",
    "    \n",
    "    return {'brier': brier_val, 'logloss': logloss_val, 'accuracy': accuracy_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:22:38.327253Z",
     "iopub.status.busy": "2025-05-04T14:22:38.326903Z",
     "iopub.status.idle": "2025-05-04T14:22:38.332165Z",
     "shell.execute_reply": "2025-05-04T14:22:38.331072Z",
     "shell.execute_reply.started": "2025-05-04T14:22:38.327229Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Extract feature names (excluding Season column)\n",
    "features = [col for col in X.columns if col != 'Season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:22:44.471194Z",
     "iopub.status.busy": "2025-05-04T14:22:44.470871Z",
     "iopub.status.idle": "2025-05-04T14:22:44.477465Z",
     "shell.execute_reply": "2025-05-04T14:22:44.476586Z",
     "shell.execute_reply.started": "2025-05-04T14:22:44.471172Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SeedDiff',\n",
       " 'WinPctDiff',\n",
       " 'PointsForDiff',\n",
       " 'PointsAgainstDiff',\n",
       " 'AvgMarginDiff',\n",
       " 'Team1Games',\n",
       " 'Team2Games',\n",
       " 'Last14WinRateDiff',\n",
       " 'NeutralWinRateDiff']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display available features\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:38:15.009642Z",
     "iopub.status.busy": "2025-05-04T14:38:15.008834Z",
     "iopub.status.idle": "2025-05-04T14:38:15.014605Z",
     "shell.execute_reply": "2025-05-04T14:38:15.013594Z",
     "shell.execute_reply.started": "2025-05-04T14:38:15.009605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initial Random Forest parameters\n",
    "rf_param = dict(\n",
    "    n_estimators=209,\n",
    "    max_depth=8,\n",
    "    min_samples_split=16,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection with Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T15:17:42.417929Z",
     "iopub.status.busy": "2025-05-04T15:17:42.417557Z",
     "iopub.status.idle": "2025-05-04T15:27:48.051232Z",
     "shell.execute_reply": "2025-05-04T15:27:48.050101Z",
     "shell.execute_reply.started": "2025-05-04T15:17:42.417903Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è  Forward selection with multi-step look-ahead\n",
      "Initial feature Brier = 0.179039\n",
      "  ‚ûï WinPctDiff                ‚Üí Brier 0.179603\n",
      "  ‚ûï PointsForDiff             ‚Üí Brier 0.179004\n",
      "  ‚ûï PointsAgainstDiff         ‚Üí Brier 0.180809\n",
      "  ‚ûï AvgMarginDiff             ‚Üí Brier 0.175713\n",
      "  ‚ûï Team1Games                ‚Üí Brier 0.182039\n",
      "  ‚ûï Team2Games                ‚Üí Brier 0.182287\n",
      "  ‚ûï Last14WinRateDiff         ‚Üí Brier 0.180066\n",
      "  ‚ûï NeutralWinRateDiff        ‚Üí Brier 0.181449\n",
      "‚úÖ  Added AvgMarginDiff             ‚Üí New Brier 0.175713\n",
      "  ‚ûï WinPctDiff                ‚Üí Brier 0.173547\n",
      "  ‚ûï PointsForDiff             ‚Üí Brier 0.175346\n",
      "  ‚ûï PointsAgainstDiff         ‚Üí Brier 0.175033\n",
      "  ‚ûï Team1Games                ‚Üí Brier 0.176170\n",
      "  ‚ûï Team2Games                ‚Üí Brier 0.176117\n",
      "  ‚ûï Last14WinRateDiff         ‚Üí Brier 0.174869\n",
      "  ‚ûï NeutralWinRateDiff        ‚Üí Brier 0.175429\n",
      "‚úÖ  Added WinPctDiff                ‚Üí New Brier 0.173547\n",
      "  ‚ûï PointsForDiff             ‚Üí Brier 0.173704\n",
      "  ‚ûï PointsAgainstDiff         ‚Üí Brier 0.173967\n",
      "  ‚ûï Team1Games                ‚Üí Brier 0.173880\n",
      "  ‚ûï Team2Games                ‚Üí Brier 0.173466\n",
      "  ‚ûï Last14WinRateDiff         ‚Üí Brier 0.173623\n",
      "  ‚ûï NeutralWinRateDiff        ‚Üí Brier 0.174206\n",
      "‚úÖ  Added Team2Games                ‚Üí New Brier 0.173466\n",
      "  ‚ûï PointsForDiff             ‚Üí Brier 0.173426\n",
      "  ‚ûï PointsAgainstDiff         ‚Üí Brier 0.173521\n",
      "  ‚ûï Team1Games                ‚Üí Brier 0.172991\n",
      "  ‚ûï Last14WinRateDiff         ‚Üí Brier 0.173565\n",
      "  ‚ûï NeutralWinRateDiff        ‚Üí Brier 0.174198\n",
      "‚úÖ  Added Team1Games                ‚Üí New Brier 0.172991\n",
      "  ‚ûï PointsForDiff             ‚Üí Brier 0.173861\n",
      "  ‚ûï PointsAgainstDiff         ‚Üí Brier 0.173710\n",
      "  ‚ûï Last14WinRateDiff         ‚Üí Brier 0.173249\n",
      "  ‚ûï NeutralWinRateDiff        ‚Üí Brier 0.173988\n",
      "  üîç Testing pair (Last14WinRateDiff, PointsAgainstDiff) ‚Üí Brier 0.173436\n",
      "  üîç Testing pair (Last14WinRateDiff, PointsForDiff) ‚Üí Brier 0.173763\n",
      "  üîç Testing pair (Last14WinRateDiff, NeutralWinRateDiff) ‚Üí Brier 0.173482\n",
      "  üîç Testing pair (PointsAgainstDiff, PointsForDiff) ‚Üí Brier 0.174616\n",
      "  üîç Testing pair (PointsAgainstDiff, NeutralWinRateDiff) ‚Üí Brier 0.174228\n",
      "  üîç Testing pair (PointsForDiff, NeutralWinRateDiff) ‚Üí Brier 0.174036\n",
      "‚öóÔ∏è  Trying to replace last single 'Team1Games' with a better pair...\n",
      "  üîç Replace-pair (PointsForDiff, PointsAgainstDiff) ‚Üí Brier 0.174399\n",
      "  üîç Replace-pair (PointsForDiff, Last14WinRateDiff) ‚Üí Brier 0.173923\n",
      "  üîç Replace-pair (PointsForDiff, NeutralWinRateDiff) ‚Üí Brier 0.174229\n",
      "  üîç Replace-pair (PointsAgainstDiff, Last14WinRateDiff) ‚Üí Brier 0.173855\n",
      "  üîç Replace-pair (PointsAgainstDiff, NeutralWinRateDiff) ‚Üí Brier 0.174466\n",
      "  üîç Replace-pair (Last14WinRateDiff, NeutralWinRateDiff) ‚Üí Brier 0.174160\n",
      "  üîç Testing best-3 ['Last14WinRateDiff', 'PointsAgainstDiff', 'PointsForDiff'] ‚Üí Brier 0.174221\n",
      "\n",
      "üèÅ  Selection complete\n",
      "Final features (5): ['SeedDiff', 'AvgMarginDiff', 'WinPctDiff', 'Team2Games', 'Team1Games']\n",
      "Final CV-Brier: 0.172991\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Forward feature selection with pair, \"remove-and-pair\", triple look-ahead\n",
    "# -------------------------------------------------------------\n",
    "start_season = 2010\n",
    "tol = 1e-5  # Tolerance for improvement\n",
    "K_PAIRS = 6  # Top-K singles to combine into pairs\n",
    "\n",
    "def evaluate_subset(feats, rf_param, start_season=start_season):\n",
    "    \"\"\"Return mean Brier score for a feature subset via rolling CV.\"\"\"\n",
    "    feats_with_season = ['Season'] + feats if 'Season' not in feats else feats\n",
    "    X_sub = X[feats_with_season].copy()\n",
    "\n",
    "    cv = rolling_window_cv(\n",
    "        X_sub, y, start_season=start_season,\n",
    "        model_fn=rf_model_fn, model_params=rf_param, verbose=False\n",
    "    )\n",
    "    return cv['brier'].mean() if not cv.empty else np.inf\n",
    "\n",
    "print(\"‚öôÔ∏è  Forward selection with multi-step look-ahead\")\n",
    "\n",
    "# Initialize ---------------------------------------------------\n",
    "selected = ['SeedDiff']\n",
    "remaining = [f for f in features if f not in selected]\n",
    "current_brier = evaluate_subset(selected, rf_param)\n",
    "print(f\"Initial feature Brier = {current_brier:.6f}\")\n",
    "\n",
    "last_single_added = None  # Tracks last feature added by Step-1\n",
    "\n",
    "# Main loop ----------------------------------------------------\n",
    "improved = True\n",
    "while remaining and improved:\n",
    "    improved = False\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 1) SINGLE-FEATURE SCAN\n",
    "    # ---------------------------------------------------------\n",
    "    single_scores = []\n",
    "    for feat in remaining:\n",
    "        b = evaluate_subset(selected + [feat], rf_param)\n",
    "        single_scores.append((feat, b))\n",
    "        print(f\"  ‚ûï {feat:<25} ‚Üí Brier {b:.6f}\")\n",
    "\n",
    "    best_feat, best_brier = min(single_scores, key=lambda x: x[1])\n",
    "\n",
    "    if best_brier < current_brier - tol:\n",
    "        selected.append(best_feat)\n",
    "        remaining.remove(best_feat)\n",
    "        current_brier = best_brier\n",
    "        last_single_added = best_feat\n",
    "        improved = True\n",
    "        print(f\"‚úÖ  Added {best_feat:<25} ‚Üí New Brier {current_brier:.6f}\")\n",
    "        continue\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2) LOOK-AHEAD WITH SEVERAL 2-FEATURE COMBINATIONS\n",
    "    # ---------------------------------------------------------\n",
    "    single_scores.sort(key=lambda x: x[1])  # Best singles first\n",
    "    top_k = single_scores[:min(K_PAIRS, len(single_scores))]\n",
    "\n",
    "    best_pair = None\n",
    "    best_pair_brier = current_brier\n",
    "    for i in range(len(top_k)):\n",
    "        f1 = top_k[i][0]\n",
    "        for j in range(i + 1, len(top_k)):\n",
    "            f2 = top_k[j][0]\n",
    "            b = evaluate_subset(selected + [f1, f2], rf_param)\n",
    "            print(f\"  üîç Testing pair ({f1}, {f2}) ‚Üí Brier {b:.6f}\")\n",
    "            if b < best_pair_brier - tol:\n",
    "                best_pair_brier = b\n",
    "                best_pair = (f1, f2)\n",
    "\n",
    "    if best_pair is not None:\n",
    "        selected.extend(best_pair)\n",
    "        for f in best_pair:\n",
    "            remaining.remove(f)\n",
    "        current_brier = best_pair_brier\n",
    "        last_single_added = None  # We added two at once\n",
    "        improved = True\n",
    "        print(f\"‚úÖ  Added pair {best_pair} ‚Üí New Brier {current_brier:.6f}\")\n",
    "        continue\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2.5) \"REMOVE-AND-PAIR\" LOOK-AHEAD\n",
    "    # ---------------------------------------------------------\n",
    "    if last_single_added is not None:\n",
    "        print(f\"‚öóÔ∏è  Trying to replace last single '{last_single_added}' with a better pair...\")\n",
    "        # Create candidate subset WITHOUT that last single\n",
    "        candidate_selected = [f for f in selected if f != last_single_added]\n",
    "        # Candidate remaining list: current remaining + the dropped feature\n",
    "        candidate_remaining = remaining + [last_single_added]\n",
    "\n",
    "        # Recompute single scores for candidate_remaining\n",
    "        cand_single_scores = []\n",
    "        for feat in candidate_remaining:\n",
    "            b = evaluate_subset(candidate_selected + [feat], rf_param)\n",
    "            cand_single_scores.append((feat, b))\n",
    "        cand_single_scores.sort(key=lambda x: x[1])\n",
    "        top_k_cand = cand_single_scores[:min(K_PAIRS, len(cand_single_scores))]\n",
    "\n",
    "        best_pair2 = None\n",
    "        best_pair2_brier = current_brier\n",
    "        for i in range(len(top_k_cand)):\n",
    "            f1 = top_k_cand[i][0]\n",
    "            if f1 == last_single_added:\n",
    "                continue\n",
    "            for j in range(i + 1, len(top_k_cand)):\n",
    "                f2 = top_k_cand[j][0]\n",
    "                if f2 == last_single_added:\n",
    "                    continue\n",
    "                b = evaluate_subset(candidate_selected + [f1, f2], rf_param)\n",
    "                print(f\"  üîç Replace-pair ({f1}, {f2}) ‚Üí Brier {b:.6f}\")\n",
    "                if b < best_pair2_brier - tol:\n",
    "                    best_pair2_brier = b\n",
    "                    best_pair2 = (f1, f2)\n",
    "\n",
    "        if best_pair2 is not None:\n",
    "            # Commit the change\n",
    "            selected = candidate_selected + list(best_pair2)\n",
    "            # Rebuild remaining\n",
    "            remaining = [f for f in candidate_remaining if f not in best_pair2]\n",
    "            current_brier = best_pair2_brier\n",
    "            last_single_added = None  # We removed it\n",
    "            improved = True\n",
    "            print(f\"‚úÖ  Replaced '{last_single_added}' with pair {best_pair2} \"\n",
    "                  f\"‚Üí New Brier {current_brier:.6f}\")\n",
    "            continue\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3) LOOK-AHEAD WITH BEST 3 FEATURES\n",
    "    # ---------------------------------------------------------\n",
    "    if len(single_scores) >= 3:\n",
    "        triple = [single_scores[i][0] for i in range(3)]\n",
    "        triple_brier = evaluate_subset(selected + triple, rf_param)\n",
    "        print(f\"  üîç Testing best-3 {triple} ‚Üí Brier {triple_brier:.6f}\")\n",
    "        if triple_brier < current_brier - tol:\n",
    "            selected.extend(triple)\n",
    "            for f in triple:\n",
    "                remaining.remove(f)\n",
    "            current_brier = triple_brier\n",
    "            last_single_added = None  # We added three\n",
    "            improved = True\n",
    "            print(f\"‚úÖ  Added triple {tuple(triple)} ‚Üí New Brier {current_brier:.6f}\")\n",
    "\n",
    "# Summary ------------------------------------------------------\n",
    "print(\"\\nüèÅ  Selection complete\")\n",
    "print(f\"Final features ({len(selected)}): {selected}\")\n",
    "print(f\"Final CV-Brier: {current_brier:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T15:32:09.656412Z",
     "iopub.status.busy": "2025-05-04T15:32:09.655985Z",
     "iopub.status.idle": "2025-05-04T15:32:28.342712Z",
     "shell.execute_reply": "2025-05-04T15:32:28.341905Z",
     "shell.execute_reply.started": "2025-05-04T15:32:09.656387Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.17447778286387264)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Brier score using all features for comparison\n",
    "evaluate_subset(features, rf_param, start_season=start_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T15:36:58.266912Z",
     "iopub.status.busy": "2025-05-04T15:36:58.266586Z",
     "iopub.status.idle": "2025-05-04T15:36:58.273750Z",
     "shell.execute_reply": "2025-05-04T15:36:58.272742Z",
     "shell.execute_reply.started": "2025-05-04T15:36:58.266887Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SeedDiff', 'AvgMarginDiff', 'WinPctDiff', 'Team2Games', 'Team1Games']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the selected features\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T15:36:58.890672Z",
     "iopub.status.busy": "2025-05-04T15:36:58.890357Z",
     "iopub.status.idle": "2025-05-04T15:36:58.906118Z",
     "shell.execute_reply": "2025-05-04T15:36:58.905100Z",
     "shell.execute_reply.started": "2025-05-04T15:36:58.890649Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>SeedDiff</th>\n",
       "      <th>AvgMarginDiff</th>\n",
       "      <th>WinPctDiff</th>\n",
       "      <th>Team2Games</th>\n",
       "      <th>Team1Games</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.830303</td>\n",
       "      <td>-0.030303</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.110345</td>\n",
       "      <td>-0.059310</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>-15</td>\n",
       "      <td>20.114943</td>\n",
       "      <td>0.546616</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>2.177249</td>\n",
       "      <td>0.062169</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>-11</td>\n",
       "      <td>1.077778</td>\n",
       "      <td>0.025926</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8063</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>-20.246976</td>\n",
       "      <td>-0.193548</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8064</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.951613</td>\n",
       "      <td>-0.089718</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8065</th>\n",
       "      <td>2023</td>\n",
       "      <td>-1</td>\n",
       "      <td>14.156250</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8066</th>\n",
       "      <td>2023</td>\n",
       "      <td>-2</td>\n",
       "      <td>-10.915054</td>\n",
       "      <td>-0.062366</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>2023</td>\n",
       "      <td>-1</td>\n",
       "      <td>-10.179167</td>\n",
       "      <td>-0.120833</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8068 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season  SeedDiff  AvgMarginDiff  WinPctDiff  Team2Games  Team1Games\n",
       "0       1985         1      -6.830303   -0.030303          30          33\n",
       "1       1985         5      -0.110345   -0.059310          25          29\n",
       "2       1985       -15      20.114943    0.546616          29          27\n",
       "3       1985         1       2.177249    0.062169          28          27\n",
       "4       1985       -11       1.077778    0.025926          27          30\n",
       "...      ...       ...            ...         ...         ...         ...\n",
       "8063    2023         1     -20.246976   -0.193548          32          31\n",
       "8064    2023         2      -2.951613   -0.089718          31          32\n",
       "8065    2023        -1      14.156250    0.187500          32          32\n",
       "8066    2023        -2     -10.915054   -0.062366          30          31\n",
       "8067    2023        -1     -10.179167   -0.120833          30          32\n",
       "\n",
       "[8068 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update dataset to include only selected features plus Season\n",
    "feats_with_season = ['Season'] + selected if 'Season' not in selected else selected\n",
    "X = X[feats_with_season]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T15:38:39.579348Z",
     "iopub.status.busy": "2025-05-04T15:38:39.578887Z",
     "iopub.status.idle": "2025-05-04T15:48:27.911706Z",
     "shell.execute_reply": "2025-05-04T15:48:27.910500Z",
     "shell.execute_reply.started": "2025-05-04T15:38:39.579322Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 14:15:05,375] A new study created in memory with name: no-name-50cc67f3-dd66-419e-8d3a-1ebe6e886986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning for window_size = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 14:15:07,571] Trial 0 finished with value: 0.17885201921466795 and parameters: {'n_estimators': 69, 'max_depth': 19, 'min_samples_split': 14}. Best is trial 0 with value: 0.17885201921466795.\n",
      "[I 2025-05-06 14:15:09,999] Trial 1 finished with value: 0.1779213843781777 and parameters: {'n_estimators': 81, 'max_depth': 10, 'min_samples_split': 7}. Best is trial 1 with value: 0.1779213843781777.\n",
      "[I 2025-05-06 14:15:11,244] Trial 2 finished with value: 0.17539443474224514 and parameters: {'n_estimators': 58, 'max_depth': 5, 'min_samples_split': 7}. Best is trial 2 with value: 0.17539443474224514.\n",
      "[I 2025-05-06 14:15:18,252] Trial 3 finished with value: 0.17607950120786825 and parameters: {'n_estimators': 260, 'max_depth': 9, 'min_samples_split': 10}. Best is trial 2 with value: 0.17539443474224514.\n",
      "[I 2025-05-06 14:15:20,276] Trial 4 finished with value: 0.18235542681945013 and parameters: {'n_estimators': 60, 'max_depth': 18, 'min_samples_split': 6}. Best is trial 2 with value: 0.17539443474224514.\n",
      "[I 2025-05-06 14:15:23,766] Trial 5 finished with value: 0.18262438395173386 and parameters: {'n_estimators': 93, 'max_depth': 14, 'min_samples_split': 3}. Best is trial 2 with value: 0.17539443474224514.\n",
      "[I 2025-05-06 14:15:26,379] Trial 6 finished with value: 0.17941837787966772 and parameters: {'n_estimators': 76, 'max_depth': 15, 'min_samples_split': 10}. Best is trial 2 with value: 0.17539443474224514.\n",
      "[I 2025-05-06 14:15:30,698] Trial 7 finished with value: 0.17746355953691512 and parameters: {'n_estimators': 146, 'max_depth': 9, 'min_samples_split': 2}. Best is trial 2 with value: 0.17539443474224514.\n",
      "[I 2025-05-06 14:15:37,347] Trial 8 finished with value: 0.17457433950938442 and parameters: {'n_estimators': 293, 'max_depth': 6, 'min_samples_split': 9}. Best is trial 8 with value: 0.17457433950938442.\n",
      "[I 2025-05-06 14:15:42,944] Trial 9 finished with value: 0.1768946004039917 and parameters: {'n_estimators': 195, 'max_depth': 14, 'min_samples_split': 19}. Best is trial 8 with value: 0.17457433950938442.\n",
      "[I 2025-05-06 14:15:48,852] Trial 10 finished with value: 0.17532822803580417 and parameters: {'n_estimators': 300, 'max_depth': 5, 'min_samples_split': 17}. Best is trial 8 with value: 0.17457433950938442.\n",
      "[I 2025-05-06 14:15:56,155] Trial 11 finished with value: 0.1753529674317738 and parameters: {'n_estimators': 298, 'max_depth': 5, 'min_samples_split': 16}. Best is trial 8 with value: 0.17457433950938442.\n",
      "[I 2025-05-06 14:16:02,736] Trial 12 finished with value: 0.174559360647659 and parameters: {'n_estimators': 251, 'max_depth': 7, 'min_samples_split': 20}. Best is trial 12 with value: 0.174559360647659.\n",
      "[I 2025-05-06 14:16:08,774] Trial 13 finished with value: 0.17544164732944448 and parameters: {'n_estimators': 234, 'max_depth': 8, 'min_samples_split': 13}. Best is trial 12 with value: 0.174559360647659.\n",
      "[I 2025-05-06 14:16:14,707] Trial 14 finished with value: 0.1747624574553405 and parameters: {'n_estimators': 250, 'max_depth': 7, 'min_samples_split': 19}. Best is trial 12 with value: 0.174559360647659.\n",
      "[I 2025-05-06 14:16:21,067] Trial 15 finished with value: 0.17736322567789023 and parameters: {'n_estimators': 205, 'max_depth': 11, 'min_samples_split': 12}. Best is trial 12 with value: 0.174559360647659.\n",
      "[I 2025-05-06 14:16:25,368] Trial 16 finished with value: 0.17553130682096996 and parameters: {'n_estimators': 150, 'max_depth': 7, 'min_samples_split': 9}. Best is trial 12 with value: 0.174559360647659.\n",
      "[I 2025-05-06 14:16:34,744] Trial 17 finished with value: 0.17675248972602467 and parameters: {'n_estimators': 275, 'max_depth': 12, 'min_samples_split': 16}. Best is trial 12 with value: 0.174559360647659.\n",
      "[I 2025-05-06 14:16:39,766] Trial 18 finished with value: 0.17492801809387754 and parameters: {'n_estimators': 220, 'max_depth': 6, 'min_samples_split': 5}. Best is trial 12 with value: 0.174559360647659.\n",
      "[I 2025-05-06 14:16:47,962] Trial 19 finished with value: 0.1770707713587686 and parameters: {'n_estimators': 272, 'max_depth': 16, 'min_samples_split': 20}. Best is trial 12 with value: 0.174559360647659.\n",
      "[I 2025-05-06 14:16:47,963] A new study created in memory with name: no-name-4da25956-f999-4750-a608-9cdea260ac44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for window_size=10: {'n_estimators': 251, 'max_depth': 7, 'min_samples_split': 20}, with avg Brier = 0.1746\n",
      "\n",
      "Tuning for window_size = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 14:16:59,790] Trial 0 finished with value: 0.17740846114303785 and parameters: {'n_estimators': 238, 'max_depth': 12, 'min_samples_split': 2}. Best is trial 0 with value: 0.17740846114303785.\n",
      "[I 2025-05-06 14:17:08,992] Trial 1 finished with value: 0.17651776569014604 and parameters: {'n_estimators': 197, 'max_depth': 19, 'min_samples_split': 16}. Best is trial 1 with value: 0.17651776569014604.\n",
      "[I 2025-05-06 14:17:12,907] Trial 2 finished with value: 0.17394772231509764 and parameters: {'n_estimators': 117, 'max_depth': 7, 'min_samples_split': 8}. Best is trial 2 with value: 0.17394772231509764.\n",
      "[I 2025-05-06 14:17:24,002] Trial 3 finished with value: 0.17364825338108256 and parameters: {'n_estimators': 294, 'max_depth': 8, 'min_samples_split': 14}. Best is trial 3 with value: 0.17364825338108256.\n",
      "[I 2025-05-06 14:17:30,837] Trial 4 finished with value: 0.17432913932598929 and parameters: {'n_estimators': 209, 'max_depth': 6, 'min_samples_split': 15}. Best is trial 3 with value: 0.17364825338108256.\n",
      "[I 2025-05-06 14:17:40,174] Trial 5 finished with value: 0.17723269496726854 and parameters: {'n_estimators': 201, 'max_depth': 13, 'min_samples_split': 3}. Best is trial 3 with value: 0.17364825338108256.\n",
      "[I 2025-05-06 14:17:49,962] Trial 6 finished with value: 0.17672520615074422 and parameters: {'n_estimators': 235, 'max_depth': 11, 'min_samples_split': 3}. Best is trial 3 with value: 0.17364825338108256.\n",
      "[I 2025-05-06 14:18:02,812] Trial 7 finished with value: 0.17453658105271336 and parameters: {'n_estimators': 299, 'max_depth': 11, 'min_samples_split': 13}. Best is trial 3 with value: 0.17364825338108256.\n",
      "[I 2025-05-06 14:18:12,942] Trial 8 finished with value: 0.17701278399016665 and parameters: {'n_estimators': 231, 'max_depth': 18, 'min_samples_split': 13}. Best is trial 3 with value: 0.17364825338108256.\n",
      "[I 2025-05-06 14:18:26,394] Trial 9 finished with value: 0.17820838544174805 and parameters: {'n_estimators': 278, 'max_depth': 13, 'min_samples_split': 2}. Best is trial 3 with value: 0.17364825338108256.\n",
      "[I 2025-05-06 14:18:28,304] Trial 10 finished with value: 0.17380933689925884 and parameters: {'n_estimators': 52, 'max_depth': 8, 'min_samples_split': 20}. Best is trial 3 with value: 0.17364825338108256.\n",
      "[I 2025-05-06 14:18:30,367] Trial 11 finished with value: 0.1734838239353439 and parameters: {'n_estimators': 60, 'max_depth': 8, 'min_samples_split': 20}. Best is trial 11 with value: 0.1734838239353439.\n",
      "[I 2025-05-06 14:18:35,230] Trial 12 finished with value: 0.17407576121216942 and parameters: {'n_estimators': 137, 'max_depth': 9, 'min_samples_split': 20}. Best is trial 11 with value: 0.1734838239353439.\n",
      "[I 2025-05-06 14:18:37,931] Trial 13 finished with value: 0.1761484326320523 and parameters: {'n_estimators': 64, 'max_depth': 15, 'min_samples_split': 17}. Best is trial 11 with value: 0.1734838239353439.\n",
      "[I 2025-05-06 14:18:41,553] Trial 14 finished with value: 0.17480554022848097 and parameters: {'n_estimators': 141, 'max_depth': 5, 'min_samples_split': 9}. Best is trial 11 with value: 0.1734838239353439.\n",
      "[I 2025-05-06 14:18:45,653] Trial 15 finished with value: 0.17427659301328485 and parameters: {'n_estimators': 105, 'max_depth': 9, 'min_samples_split': 18}. Best is trial 11 with value: 0.1734838239353439.\n",
      "[I 2025-05-06 14:18:50,452] Trial 16 finished with value: 0.17486233406942625 and parameters: {'n_estimators': 160, 'max_depth': 5, 'min_samples_split': 11}. Best is trial 11 with value: 0.1734838239353439.\n",
      "[I 2025-05-06 14:18:55,909] Trial 17 finished with value: 0.17954610741563756 and parameters: {'n_estimators': 91, 'max_depth': 16, 'min_samples_split': 6}. Best is trial 11 with value: 0.1734838239353439.\n",
      "[I 2025-05-06 14:19:05,559] Trial 18 finished with value: 0.17427034189372287 and parameters: {'n_estimators': 264, 'max_depth': 9, 'min_samples_split': 13}. Best is trial 11 with value: 0.1734838239353439.\n",
      "[I 2025-05-06 14:19:10,824] Trial 19 finished with value: 0.17397537501789168 and parameters: {'n_estimators': 167, 'max_depth': 7, 'min_samples_split': 18}. Best is trial 11 with value: 0.1734838239353439.\n",
      "[I 2025-05-06 14:19:10,826] A new study created in memory with name: no-name-1e36b779-6da7-42c0-b8e0-0f098537f3c9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for window_size=15: {'n_estimators': 60, 'max_depth': 8, 'min_samples_split': 20}, with avg Brier = 0.1735\n",
      "\n",
      "Tuning for window_size = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 14:19:29,172] Trial 0 finished with value: 0.1794160483058101 and parameters: {'n_estimators': 298, 'max_depth': 15, 'min_samples_split': 4}. Best is trial 0 with value: 0.1794160483058101.\n",
      "[I 2025-05-06 14:19:39,019] Trial 1 finished with value: 0.1738758718111077 and parameters: {'n_estimators': 242, 'max_depth': 8, 'min_samples_split': 14}. Best is trial 1 with value: 0.1738758718111077.\n",
      "[I 2025-05-06 14:19:42,174] Trial 2 finished with value: 0.17556636638520423 and parameters: {'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 17}. Best is trial 1 with value: 0.1738758718111077.\n",
      "[I 2025-05-06 14:19:51,368] Trial 3 finished with value: 0.17972796503679128 and parameters: {'n_estimators': 143, 'max_depth': 14, 'min_samples_split': 3}. Best is trial 1 with value: 0.1738758718111077.\n",
      "[I 2025-05-06 14:20:01,449] Trial 4 finished with value: 0.17415810304495644 and parameters: {'n_estimators': 260, 'max_depth': 6, 'min_samples_split': 7}. Best is trial 1 with value: 0.1738758718111077.\n",
      "[I 2025-05-06 14:20:12,636] Trial 5 finished with value: 0.1784316863183939 and parameters: {'n_estimators': 187, 'max_depth': 19, 'min_samples_split': 9}. Best is trial 1 with value: 0.1738758718111077.\n",
      "[I 2025-05-06 14:20:29,396] Trial 6 finished with value: 0.17608857373342388 and parameters: {'n_estimators': 271, 'max_depth': 18, 'min_samples_split': 18}. Best is trial 1 with value: 0.1738758718111077.\n",
      "[I 2025-05-06 14:20:38,091] Trial 7 finished with value: 0.1788959495312458 and parameters: {'n_estimators': 146, 'max_depth': 13, 'min_samples_split': 3}. Best is trial 1 with value: 0.1738758718111077.\n",
      "[I 2025-05-06 14:20:41,780] Trial 8 finished with value: 0.18203485933811367 and parameters: {'n_estimators': 62, 'max_depth': 18, 'min_samples_split': 4}. Best is trial 1 with value: 0.1738758718111077.\n",
      "[I 2025-05-06 14:20:51,997] Trial 9 finished with value: 0.17413711309323152 and parameters: {'n_estimators': 194, 'max_depth': 9, 'min_samples_split': 11}. Best is trial 1 with value: 0.1738758718111077.\n",
      "[I 2025-05-06 14:21:03,698] Trial 10 finished with value: 0.17428853796635016 and parameters: {'n_estimators': 220, 'max_depth': 9, 'min_samples_split': 14}. Best is trial 1 with value: 0.1738758718111077.\n",
      "[I 2025-05-06 14:21:14,188] Trial 11 finished with value: 0.17462602082336368 and parameters: {'n_estimators': 217, 'max_depth': 9, 'min_samples_split': 13}. Best is trial 1 with value: 0.1738758718111077.\n",
      "[I 2025-05-06 14:21:25,081] Trial 12 finished with value: 0.17463155896092925 and parameters: {'n_estimators': 227, 'max_depth': 9, 'min_samples_split': 12}. Best is trial 1 with value: 0.1738758718111077.\n",
      "[I 2025-05-06 14:21:34,223] Trial 13 finished with value: 0.17525862951116442 and parameters: {'n_estimators': 175, 'max_depth': 11, 'min_samples_split': 15}. Best is trial 1 with value: 0.1738758718111077.\n",
      "[I 2025-05-06 14:21:44,802] Trial 14 finished with value: 0.17354202893136855 and parameters: {'n_estimators': 251, 'max_depth': 7, 'min_samples_split': 10}. Best is trial 14 with value: 0.17354202893136855.\n",
      "[I 2025-05-06 14:21:55,010] Trial 15 finished with value: 0.17370605296045608 and parameters: {'n_estimators': 253, 'max_depth': 7, 'min_samples_split': 8}. Best is trial 14 with value: 0.17354202893136855.\n",
      "[I 2025-05-06 14:22:07,625] Trial 16 finished with value: 0.17370754873037494 and parameters: {'n_estimators': 294, 'max_depth': 7, 'min_samples_split': 8}. Best is trial 14 with value: 0.17354202893136855.\n",
      "[I 2025-05-06 14:22:21,349] Trial 17 finished with value: 0.17536358524233858 and parameters: {'n_estimators': 261, 'max_depth': 11, 'min_samples_split': 7}. Best is trial 14 with value: 0.17354202893136855.\n",
      "[I 2025-05-06 14:22:30,400] Trial 18 finished with value: 0.17502268163622703 and parameters: {'n_estimators': 274, 'max_depth': 5, 'min_samples_split': 10}. Best is trial 14 with value: 0.17354202893136855.\n",
      "[I 2025-05-06 14:22:43,499] Trial 19 finished with value: 0.1759314221073199 and parameters: {'n_estimators': 242, 'max_depth': 11, 'min_samples_split': 6}. Best is trial 14 with value: 0.17354202893136855.\n",
      "[I 2025-05-06 14:22:43,500] A new study created in memory with name: no-name-b96aa457-e824-4828-a05b-a0c957b18f5e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for window_size=20: {'n_estimators': 251, 'max_depth': 7, 'min_samples_split': 10}, with avg Brier = 0.1735\n",
      "\n",
      "Tuning for window_size = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 14:22:50,639] Trial 0 finished with value: 0.17464271376435533 and parameters: {'n_estimators': 143, 'max_depth': 9, 'min_samples_split': 10}. Best is trial 0 with value: 0.17464271376435533.\n",
      "[I 2025-05-06 14:23:04,101] Trial 1 finished with value: 0.17822146310844608 and parameters: {'n_estimators': 192, 'max_depth': 16, 'min_samples_split': 12}. Best is trial 0 with value: 0.17464271376435533.\n",
      "[I 2025-05-06 14:23:17,928] Trial 2 finished with value: 0.17478117611176633 and parameters: {'n_estimators': 264, 'max_depth': 9, 'min_samples_split': 4}. Best is trial 0 with value: 0.17464271376435533.\n",
      "[I 2025-05-06 14:23:32,117] Trial 3 finished with value: 0.1773293994311234 and parameters: {'n_estimators': 230, 'max_depth': 19, 'min_samples_split': 15}. Best is trial 0 with value: 0.17464271376435533.\n",
      "[I 2025-05-06 14:23:43,564] Trial 4 finished with value: 0.17494594510364836 and parameters: {'n_estimators': 203, 'max_depth': 10, 'min_samples_split': 19}. Best is trial 0 with value: 0.17464271376435533.\n",
      "[I 2025-05-06 14:24:01,696] Trial 5 finished with value: 0.17784610310927146 and parameters: {'n_estimators': 258, 'max_depth': 16, 'min_samples_split': 10}. Best is trial 0 with value: 0.17464271376435533.\n",
      "[I 2025-05-06 14:24:09,511] Trial 6 finished with value: 0.17512708543404532 and parameters: {'n_estimators': 141, 'max_depth': 11, 'min_samples_split': 17}. Best is trial 0 with value: 0.17464271376435533.\n",
      "[I 2025-05-06 14:24:26,295] Trial 7 finished with value: 0.17673539124214524 and parameters: {'n_estimators': 277, 'max_depth': 15, 'min_samples_split': 16}. Best is trial 0 with value: 0.17464271376435533.\n",
      "[I 2025-05-06 14:24:28,819] Trial 8 finished with value: 0.17557306361068087 and parameters: {'n_estimators': 71, 'max_depth': 5, 'min_samples_split': 9}. Best is trial 0 with value: 0.17464271376435533.\n",
      "[I 2025-05-06 14:24:34,114] Trial 9 finished with value: 0.17435644156527305 and parameters: {'n_estimators': 102, 'max_depth': 9, 'min_samples_split': 9}. Best is trial 9 with value: 0.17435644156527305.\n",
      "[I 2025-05-06 14:24:36,325] Trial 10 finished with value: 0.17449343663893427 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 2}. Best is trial 9 with value: 0.17435644156527305.\n",
      "[I 2025-05-06 14:24:38,245] Trial 11 finished with value: 0.1756104962384915 and parameters: {'n_estimators': 54, 'max_depth': 5, 'min_samples_split': 2}. Best is trial 9 with value: 0.17435644156527305.\n",
      "[I 2025-05-06 14:24:42,527] Trial 12 finished with value: 0.17397035218992263 and parameters: {'n_estimators': 98, 'max_depth': 7, 'min_samples_split': 6}. Best is trial 12 with value: 0.17397035218992263.\n",
      "[I 2025-05-06 14:24:47,736] Trial 13 finished with value: 0.1743614607074901 and parameters: {'n_estimators': 103, 'max_depth': 8, 'min_samples_split': 7}. Best is trial 12 with value: 0.17397035218992263.\n",
      "[I 2025-05-06 14:24:55,292] Trial 14 finished with value: 0.17849530603640767 and parameters: {'n_estimators': 109, 'max_depth': 13, 'min_samples_split': 6}. Best is trial 12 with value: 0.17397035218992263.\n",
      "[I 2025-05-06 14:25:00,113] Trial 15 finished with value: 0.173898879125769 and parameters: {'n_estimators': 103, 'max_depth': 7, 'min_samples_split': 7}. Best is trial 15 with value: 0.173898879125769.\n",
      "[I 2025-05-06 14:25:06,466] Trial 16 finished with value: 0.17360962484931958 and parameters: {'n_estimators': 148, 'max_depth': 7, 'min_samples_split': 6}. Best is trial 16 with value: 0.17360962484931958.\n",
      "[I 2025-05-06 14:25:15,559] Trial 17 finished with value: 0.17614533284447775 and parameters: {'n_estimators': 154, 'max_depth': 12, 'min_samples_split': 13}. Best is trial 16 with value: 0.17360962484931958.\n",
      "[I 2025-05-06 14:25:23,786] Trial 18 finished with value: 0.173981326116679 and parameters: {'n_estimators': 173, 'max_depth': 7, 'min_samples_split': 4}. Best is trial 16 with value: 0.17360962484931958.\n",
      "[I 2025-05-06 14:25:33,401] Trial 19 finished with value: 0.18013736746604708 and parameters: {'n_estimators': 135, 'max_depth': 20, 'min_samples_split': 7}. Best is trial 16 with value: 0.17360962484931958.\n",
      "[I 2025-05-06 14:25:33,402] A new study created in memory with name: no-name-71629647-a99d-4574-9c20-8829000cbf6a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for window_size=25: {'n_estimators': 148, 'max_depth': 7, 'min_samples_split': 6}, with avg Brier = 0.1736\n",
      "\n",
      "Tuning for window_size = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 14:25:36,481] Trial 0 finished with value: 0.1750715701714844 and parameters: {'n_estimators': 54, 'max_depth': 10, 'min_samples_split': 17}. Best is trial 0 with value: 0.1750715701714844.\n",
      "[I 2025-05-06 14:25:43,072] Trial 1 finished with value: 0.1770491941391848 and parameters: {'n_estimators': 100, 'max_depth': 13, 'min_samples_split': 8}. Best is trial 0 with value: 0.1750715701714844.\n",
      "[I 2025-05-06 14:25:46,258] Trial 2 finished with value: 0.17426295234358277 and parameters: {'n_estimators': 56, 'max_depth': 8, 'min_samples_split': 11}. Best is trial 2 with value: 0.17426295234358277.\n",
      "[I 2025-05-06 14:26:02,000] Trial 3 finished with value: 0.17353054375128898 and parameters: {'n_estimators': 268, 'max_depth': 9, 'min_samples_split': 20}. Best is trial 3 with value: 0.17353054375128898.\n",
      "[I 2025-05-06 14:26:19,723] Trial 4 finished with value: 0.17797294053868445 and parameters: {'n_estimators': 240, 'max_depth': 19, 'min_samples_split': 11}. Best is trial 3 with value: 0.17353054375128898.\n",
      "[I 2025-05-06 14:26:34,302] Trial 5 finished with value: 0.1735519907802195 and parameters: {'n_estimators': 286, 'max_depth': 8, 'min_samples_split': 5}. Best is trial 3 with value: 0.17353054375128898.\n",
      "[I 2025-05-06 14:26:40,941] Trial 6 finished with value: 0.17335812221368235 and parameters: {'n_estimators': 146, 'max_depth': 7, 'min_samples_split': 18}. Best is trial 6 with value: 0.17335812221368235.\n",
      "[I 2025-05-06 14:26:47,349] Trial 7 finished with value: 0.1785602734048614 and parameters: {'n_estimators': 89, 'max_depth': 17, 'min_samples_split': 13}. Best is trial 6 with value: 0.17335812221368235.\n",
      "[I 2025-05-06 14:27:08,211] Trial 8 finished with value: 0.18192301872828193 and parameters: {'n_estimators': 255, 'max_depth': 20, 'min_samples_split': 4}. Best is trial 6 with value: 0.17335812221368235.\n",
      "[I 2025-05-06 14:27:25,126] Trial 9 finished with value: 0.18053297829449572 and parameters: {'n_estimators': 224, 'max_depth': 19, 'min_samples_split': 5}. Best is trial 6 with value: 0.17335812221368235.\n",
      "[I 2025-05-06 14:27:31,490] Trial 10 finished with value: 0.17465473839565232 and parameters: {'n_estimators': 165, 'max_depth': 5, 'min_samples_split': 16}. Best is trial 6 with value: 0.17335812221368235.\n",
      "[I 2025-05-06 14:27:37,624] Trial 11 finished with value: 0.17476838686649293 and parameters: {'n_estimators': 167, 'max_depth': 5, 'min_samples_split': 20}. Best is trial 6 with value: 0.17335812221368235.\n",
      "[I 2025-05-06 14:27:50,084] Trial 12 finished with value: 0.17471651174970956 and parameters: {'n_estimators': 201, 'max_depth': 12, 'min_samples_split': 20}. Best is trial 6 with value: 0.17335812221368235.\n",
      "[I 2025-05-06 14:27:56,912] Trial 13 finished with value: 0.17357953507666965 and parameters: {'n_estimators': 133, 'max_depth': 8, 'min_samples_split': 17}. Best is trial 6 with value: 0.17335812221368235.\n",
      "[I 2025-05-06 14:28:14,673] Trial 14 finished with value: 0.17457019053451725 and parameters: {'n_estimators': 278, 'max_depth': 11, 'min_samples_split': 14}. Best is trial 6 with value: 0.17335812221368235.\n",
      "[I 2025-05-06 14:28:28,366] Trial 15 finished with value: 0.17538627348947514 and parameters: {'n_estimators': 200, 'max_depth': 14, 'min_samples_split': 20}. Best is trial 6 with value: 0.17335812221368235.\n",
      "[I 2025-05-06 14:28:35,176] Trial 16 finished with value: 0.17339472326261368 and parameters: {'n_estimators': 138, 'max_depth': 7, 'min_samples_split': 18}. Best is trial 6 with value: 0.17335812221368235.\n",
      "[I 2025-05-06 14:28:40,674] Trial 17 finished with value: 0.17367033179102434 and parameters: {'n_estimators': 124, 'max_depth': 6, 'min_samples_split': 15}. Best is trial 6 with value: 0.17335812221368235.\n",
      "[I 2025-05-06 14:28:50,457] Trial 18 finished with value: 0.1765092805141674 and parameters: {'n_estimators': 143, 'max_depth': 15, 'min_samples_split': 18}. Best is trial 6 with value: 0.17335812221368235.\n",
      "[I 2025-05-06 14:28:55,097] Trial 19 finished with value: 0.1732968801826147 and parameters: {'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 9}. Best is trial 19 with value: 0.1732968801826147.\n",
      "[I 2025-05-06 14:28:55,098] A new study created in memory with name: no-name-7ca17782-fa6b-40ee-8d28-32629b347330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for window_size=30: {'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 9}, with avg Brier = 0.1733\n",
      "\n",
      "Tuning for window_size = 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 14:29:01,201] Trial 0 finished with value: 0.17899302246258353 and parameters: {'n_estimators': 83, 'max_depth': 16, 'min_samples_split': 6}. Best is trial 0 with value: 0.17899302246258353.\n",
      "[I 2025-05-06 14:29:20,841] Trial 1 finished with value: 0.1814845290161585 and parameters: {'n_estimators': 239, 'max_depth': 19, 'min_samples_split': 3}. Best is trial 0 with value: 0.17899302246258353.\n",
      "[I 2025-05-06 14:29:27,680] Trial 2 finished with value: 0.1770614564108753 and parameters: {'n_estimators': 91, 'max_depth': 14, 'min_samples_split': 10}. Best is trial 2 with value: 0.1770614564108753.\n",
      "[I 2025-05-06 14:29:35,290] Trial 3 finished with value: 0.1732429681206011 and parameters: {'n_estimators': 136, 'max_depth': 8, 'min_samples_split': 9}. Best is trial 3 with value: 0.1732429681206011.\n",
      "[I 2025-05-06 14:29:50,934] Trial 4 finished with value: 0.1742504764071074 and parameters: {'n_estimators': 239, 'max_depth': 12, 'min_samples_split': 19}. Best is trial 3 with value: 0.1732429681206011.\n",
      "[I 2025-05-06 14:30:02,209] Trial 5 finished with value: 0.17757003834014734 and parameters: {'n_estimators': 156, 'max_depth': 16, 'min_samples_split': 10}. Best is trial 3 with value: 0.1732429681206011.\n",
      "[I 2025-05-06 14:30:11,258] Trial 6 finished with value: 0.17831862241208474 and parameters: {'n_estimators': 116, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 3 with value: 0.1732429681206011.\n",
      "[I 2025-05-06 14:30:18,774] Trial 7 finished with value: 0.1782709033035781 and parameters: {'n_estimators': 101, 'max_depth': 19, 'min_samples_split': 14}. Best is trial 3 with value: 0.1732429681206011.\n",
      "[I 2025-05-06 14:30:32,305] Trial 8 finished with value: 0.17485604818403946 and parameters: {'n_estimators': 206, 'max_depth': 12, 'min_samples_split': 12}. Best is trial 3 with value: 0.1732429681206011.\n",
      "[I 2025-05-06 14:30:36,414] Trial 9 finished with value: 0.17499805381214983 and parameters: {'n_estimators': 64, 'max_depth': 11, 'min_samples_split': 20}. Best is trial 3 with value: 0.1732429681206011.\n",
      "[I 2025-05-06 14:30:43,555] Trial 10 finished with value: 0.1734456036327363 and parameters: {'n_estimators': 156, 'max_depth': 6, 'min_samples_split': 15}. Best is trial 3 with value: 0.1732429681206011.\n",
      "[I 2025-05-06 14:30:50,765] Trial 11 finished with value: 0.17344956619236343 and parameters: {'n_estimators': 159, 'max_depth': 6, 'min_samples_split': 15}. Best is trial 3 with value: 0.1732429681206011.\n",
      "[I 2025-05-06 14:31:02,660] Trial 12 finished with value: 0.1746124113078956 and parameters: {'n_estimators': 283, 'max_depth': 5, 'min_samples_split': 17}. Best is trial 3 with value: 0.1732429681206011.\n",
      "[I 2025-05-06 14:31:10,221] Trial 13 finished with value: 0.1738926466026209 and parameters: {'n_estimators': 135, 'max_depth': 9, 'min_samples_split': 7}. Best is trial 3 with value: 0.1732429681206011.\n",
      "[I 2025-05-06 14:31:20,250] Trial 14 finished with value: 0.17313994151186143 and parameters: {'n_estimators': 195, 'max_depth': 8, 'min_samples_split': 13}. Best is trial 14 with value: 0.17313994151186143.\n",
      "[I 2025-05-06 14:31:31,250] Trial 15 finished with value: 0.17357816455785208 and parameters: {'n_estimators': 199, 'max_depth': 9, 'min_samples_split': 12}. Best is trial 14 with value: 0.17313994151186143.\n",
      "[I 2025-05-06 14:31:42,307] Trial 16 finished with value: 0.1732978724755134 and parameters: {'n_estimators': 196, 'max_depth': 8, 'min_samples_split': 2}. Best is trial 14 with value: 0.17313994151186143.\n",
      "[I 2025-05-06 14:31:54,442] Trial 17 finished with value: 0.17315058753251603 and parameters: {'n_estimators': 234, 'max_depth': 8, 'min_samples_split': 9}. Best is trial 14 with value: 0.17313994151186143.\n",
      "[I 2025-05-06 14:32:13,337] Trial 18 finished with value: 0.17368239525611834 and parameters: {'n_estimators': 287, 'max_depth': 10, 'min_samples_split': 13}. Best is trial 14 with value: 0.17313994151186143.\n",
      "[I 2025-05-06 14:32:24,958] Trial 19 finished with value: 0.17307712206207787 and parameters: {'n_estimators': 248, 'max_depth': 7, 'min_samples_split': 4}. Best is trial 19 with value: 0.17307712206207787.\n",
      "[I 2025-05-06 14:32:24,960] A new study created in memory with name: no-name-e901ce30-3e16-4503-8880-7aa05f1a10a3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for window_size=35: {'n_estimators': 248, 'max_depth': 7, 'min_samples_split': 4}, with avg Brier = 0.1731\n",
      "\n",
      "Tuning for window_size = 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-06 14:32:46,285] Trial 0 finished with value: 0.17633751545856746 and parameters: {'n_estimators': 283, 'max_depth': 15, 'min_samples_split': 12}. Best is trial 0 with value: 0.17633751545856746.\n",
      "[I 2025-05-06 14:32:51,892] Trial 1 finished with value: 0.1742626213073518 and parameters: {'n_estimators': 88, 'max_depth': 13, 'min_samples_split': 18}. Best is trial 1 with value: 0.1742626213073518.\n",
      "[I 2025-05-06 14:32:57,746] Trial 2 finished with value: 0.17769540320994393 and parameters: {'n_estimators': 77, 'max_depth': 20, 'min_samples_split': 14}. Best is trial 1 with value: 0.1742626213073518.\n",
      "[I 2025-05-06 14:33:02,271] Trial 3 finished with value: 0.17452791880029905 and parameters: {'n_estimators': 60, 'max_depth': 12, 'min_samples_split': 18}. Best is trial 1 with value: 0.1742626213073518.\n",
      "[I 2025-05-06 14:33:08,373] Trial 4 finished with value: 0.17337486248784734 and parameters: {'n_estimators': 123, 'max_depth': 6, 'min_samples_split': 14}. Best is trial 4 with value: 0.17337486248784734.\n",
      "[I 2025-05-06 14:33:11,666] Trial 5 finished with value: 0.17411483124009236 and parameters: {'n_estimators': 62, 'max_depth': 7, 'min_samples_split': 14}. Best is trial 4 with value: 0.17337486248784734.\n",
      "[I 2025-05-06 14:33:27,336] Trial 6 finished with value: 0.17335763694873604 and parameters: {'n_estimators': 295, 'max_depth': 8, 'min_samples_split': 4}. Best is trial 6 with value: 0.17335763694873604.\n",
      "[I 2025-05-06 14:33:39,001] Trial 7 finished with value: 0.17284376346798846 and parameters: {'n_estimators': 230, 'max_depth': 7, 'min_samples_split': 11}. Best is trial 7 with value: 0.17284376346798846.\n",
      "[I 2025-05-06 14:33:48,544] Trial 8 finished with value: 0.17359507700789112 and parameters: {'n_estimators': 224, 'max_depth': 6, 'min_samples_split': 19}. Best is trial 7 with value: 0.17284376346798846.\n",
      "[I 2025-05-06 14:33:57,947] Trial 9 finished with value: 0.1741674836735997 and parameters: {'n_estimators': 142, 'max_depth': 11, 'min_samples_split': 13}. Best is trial 7 with value: 0.17284376346798846.\n",
      "[I 2025-05-06 14:34:10,746] Trial 10 finished with value: 0.1737209082152627 and parameters: {'n_estimators': 210, 'max_depth': 9, 'min_samples_split': 7}. Best is trial 7 with value: 0.17284376346798846.\n",
      "[I 2025-05-06 14:34:27,102] Trial 11 finished with value: 0.17348301654799944 and parameters: {'n_estimators': 296, 'max_depth': 9, 'min_samples_split': 2}. Best is trial 7 with value: 0.17284376346798846.\n",
      "[I 2025-05-06 14:34:36,611] Trial 12 finished with value: 0.17450925911299248 and parameters: {'n_estimators': 248, 'max_depth': 5, 'min_samples_split': 7}. Best is trial 7 with value: 0.17284376346798846.\n",
      "[I 2025-05-06 14:34:50,941] Trial 13 finished with value: 0.17342794361899838 and parameters: {'n_estimators': 260, 'max_depth': 9, 'min_samples_split': 2}. Best is trial 7 with value: 0.17284376346798846.\n",
      "[I 2025-05-06 14:35:06,198] Trial 14 finished with value: 0.17804163053324312 and parameters: {'n_estimators': 192, 'max_depth': 17, 'min_samples_split': 8}. Best is trial 7 with value: 0.17284376346798846.\n",
      "[I 2025-05-06 14:35:19,625] Trial 15 finished with value: 0.17344134785139675 and parameters: {'n_estimators': 249, 'max_depth': 9, 'min_samples_split': 9}. Best is trial 7 with value: 0.17284376346798846.\n",
      "[I 2025-05-06 14:35:27,735] Trial 16 finished with value: 0.17326430946884247 and parameters: {'n_estimators': 153, 'max_depth': 7, 'min_samples_split': 4}. Best is trial 7 with value: 0.17284376346798846.\n",
      "[I 2025-05-06 14:35:34,342] Trial 17 finished with value: 0.17460047064901738 and parameters: {'n_estimators': 153, 'max_depth': 5, 'min_samples_split': 5}. Best is trial 7 with value: 0.17284376346798846.\n",
      "[I 2025-05-06 14:35:45,076] Trial 18 finished with value: 0.17451202024592288 and parameters: {'n_estimators': 177, 'max_depth': 11, 'min_samples_split': 10}. Best is trial 7 with value: 0.17284376346798846.\n",
      "[I 2025-05-06 14:35:50,243] Trial 19 finished with value: 0.17329799475694604 and parameters: {'n_estimators': 112, 'max_depth': 7, 'min_samples_split': 16}. Best is trial 7 with value: 0.17284376346798846.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for window_size=39: {'n_estimators': 230, 'max_depth': 7, 'min_samples_split': 11}, with avg Brier = 0.1728\n",
      "\n",
      "Grid search results:\n",
      "   window_size  avg_brier                                        best_params\n",
      "0           10   0.174559  {'n_estimators': 251, 'max_depth': 7, 'min_sam...\n",
      "1           15   0.173484  {'n_estimators': 60, 'max_depth': 8, 'min_samp...\n",
      "2           20   0.173542  {'n_estimators': 251, 'max_depth': 7, 'min_sam...\n",
      "3           25   0.173610  {'n_estimators': 148, 'max_depth': 7, 'min_sam...\n",
      "4           30   0.173297  {'n_estimators': 100, 'max_depth': 7, 'min_sam...\n",
      "5           35   0.173077  {'n_estimators': 248, 'max_depth': 7, 'min_sam...\n",
      "6           39   0.172844  {'n_estimators': 230, 'max_depth': 7, 'min_sam...\n",
      "\n",
      "Best overall: window_size = 39, avg Brier = 0.1728, best_params = {'n_estimators': 230, 'max_depth': 7, 'min_samples_split': 11}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X, y, start_season, window_size):\n",
    "    \"\"\"Optuna objective function for hyperparameter optimization.\"\"\"\n",
    "    # Define hyperparameter search space\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 5, 20)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
    "    \n",
    "    rf_params = dict(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state=42,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    \n",
    "    # Use the rolling_window_cv from pre_processing.py\n",
    "    metrics_df = rolling_window_cv(\n",
    "        X, y, start_season=start_season, window_size=window_size,\n",
    "        model_fn=rf_model_fn, model_params=rf_params, verbose=False\n",
    "    )\n",
    "    if metrics_df.empty:\n",
    "        return float('inf')\n",
    "    return metrics_df['brier'].mean()\n",
    "\n",
    "def tune_hyperparameters_for_window_size(X, y, start_season, window_size, n_trials=20):\n",
    "    \"\"\"Tunes hyperparameters for a specific window size.\"\"\"\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(lambda trial: objective(trial, X, y, start_season, window_size), n_trials=n_trials)\n",
    "    best_params = study.best_trial.params\n",
    "    best_value = study.best_trial.value\n",
    "    print(f\"Best hyperparameters for window_size={window_size}: {best_params}, with avg Brier = {best_value:.4f}\")\n",
    "    return best_params, best_value\n",
    "\n",
    "def grid_search_window_size_and_hyperparams(X, y, start_season, window_sizes, n_trials=20):\n",
    "    \"\"\"Performs grid search over window sizes and tunes hyperparameters for each.\"\"\"\n",
    "    records = []\n",
    "    best_overall = None\n",
    "    best_window = None\n",
    "    best_params_overall = None\n",
    "    \n",
    "    for w in window_sizes:\n",
    "        print(f\"\\nTuning for window_size = {w}\")\n",
    "        best_params, avg_brier = tune_hyperparameters_for_window_size(X, y, start_season, window_size=w, n_trials=n_trials)\n",
    "        records.append({'window_size': w, 'avg_brier': avg_brier, 'best_params': best_params})\n",
    "        if best_overall is None or avg_brier <= best_overall:\n",
    "            best_overall = avg_brier\n",
    "            best_window = w\n",
    "            best_params_overall = best_params\n",
    "    \n",
    "    results_df = pd.DataFrame(records)\n",
    "    print(\"\\nGrid search results:\")\n",
    "    print(results_df)\n",
    "    print(f\"\\nBest overall: window_size = {best_window}, avg Brier = {best_overall:.4f}, best_params = {best_params_overall}\")\n",
    "    return best_window, best_params_overall, results_df\n",
    "\n",
    "# Use all available seasons for demonstration\n",
    "demo_seasons = list(range(X['Season'].min(), X['Season'].max()+1))\n",
    "\n",
    "# Set the selected features for the input data\n",
    "X = X[feats_with_season]\n",
    "\n",
    "# Determine maximum possible window size\n",
    "max_window_size = len(demo_seasons)\n",
    "\n",
    "# Create possible window sizes starting from 10, in steps of 5\n",
    "possible_window_sizes = list(range(10, max_window_size, 5))\n",
    "\n",
    "# Ensure the max_window_size is included if it's not already\n",
    "if max_window_size not in possible_window_sizes:\n",
    "    possible_window_sizes.append(max_window_size)\n",
    "\n",
    "best_window, best_params, grid_results = grid_search_window_size_and_hyperparams(\n",
    "    X, y, start_season=2010, window_sizes=possible_window_sizes, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation with Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T15:55:18.126186Z",
     "iopub.status.busy": "2025-05-04T15:55:18.121311Z",
     "iopub.status.idle": "2025-05-04T15:55:22.883093Z",
     "shell.execute_reply": "2025-05-04T15:55:22.881920Z",
     "shell.execute_reply.started": "2025-05-04T15:55:18.126096Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation with best window size = 39 and best hyperparameters = {'n_estimators': 230, 'max_depth': 7, 'min_samples_split': 11}\n",
      "Season 2011 ‚Äì Accuracy: 0.681, Log Loss: 0.516, Brier: 0.178\n",
      "Season 2012 ‚Äì Accuracy: 0.781, Log Loss: 0.509, Brier: 0.166\n",
      "Season 2013 ‚Äì Accuracy: 0.715, Log Loss: 0.538, Brier: 0.184\n",
      "Season 2014 ‚Äì Accuracy: 0.727, Log Loss: 0.514, Brier: 0.176\n",
      "Season 2015 ‚Äì Accuracy: 0.788, Log Loss: 0.463, Brier: 0.149\n",
      "Season 2016 ‚Äì Accuracy: 0.719, Log Loss: 0.535, Brier: 0.181\n",
      "Season 2017 ‚Äì Accuracy: 0.788, Log Loss: 0.485, Brier: 0.162\n",
      "Season 2018 ‚Äì Accuracy: 0.692, Log Loss: 0.558, Brier: 0.189\n",
      "Season 2019 ‚Äì Accuracy: 0.738, Log Loss: 0.462, Brier: 0.155\n",
      "Season 2021 ‚Äì Accuracy: 0.717, Log Loss: 0.562, Brier: 0.191\n",
      "\n",
      "Overall average metrics: Accuracy: 0.735, Log Loss: 0.514, Brier: 0.173\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nFinal evaluation with best window size = {best_window} and best hyperparameters = {best_params}\")\n",
    "final_metrics_df = rolling_window_cv(\n",
    "    X, y, start_season=2010, window_size=best_window,\n",
    "    model_fn=rf_model_fn, model_params=best_params, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T15:56:16.757639Z",
     "iopub.status.busy": "2025-05-04T15:56:16.757264Z",
     "iopub.status.idle": "2025-05-04T15:56:21.988877Z",
     "shell.execute_reply": "2025-05-04T15:56:21.987925Z",
     "shell.execute_reply.started": "2025-05-04T15:56:16.757616Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation using all available training data:\n",
      "Season 2011 ‚Äì Accuracy: 0.692, Log Loss: 0.511, Brier: 0.176\n",
      "Season 2012 ‚Äì Accuracy: 0.765, Log Loss: 0.509, Brier: 0.167\n",
      "Season 2013 ‚Äì Accuracy: 0.712, Log Loss: 0.537, Brier: 0.184\n",
      "Season 2014 ‚Äì Accuracy: 0.735, Log Loss: 0.514, Brier: 0.176\n",
      "Season 2015 ‚Äì Accuracy: 0.781, Log Loss: 0.464, Brier: 0.150\n",
      "Season 2016 ‚Äì Accuracy: 0.731, Log Loss: 0.533, Brier: 0.180\n",
      "Season 2017 ‚Äì Accuracy: 0.792, Log Loss: 0.490, Brier: 0.164\n",
      "Season 2018 ‚Äì Accuracy: 0.692, Log Loss: 0.557, Brier: 0.188\n",
      "Season 2019 ‚Äì Accuracy: 0.738, Log Loss: 0.460, Brier: 0.155\n",
      "Season 2021 ‚Äì Accuracy: 0.705, Log Loss: 0.570, Brier: 0.194\n",
      "\n",
      "Overall average metrics: Accuracy: 0.734, Log Loss: 0.515, Brier: 0.173\n",
      "\n",
      "Top 5 most important features:\n",
      "         feature  importance\n",
      "0       SeedDiff    0.511106\n",
      "1  AvgMarginDiff    0.271625\n",
      "2     WinPctDiff    0.135290\n",
      "4     Team1Games    0.042462\n",
      "3     Team2Games    0.039517\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nFinal evaluation using all available training data:\")\n",
    "final_metrics_all_df = rolling_window_cv(\n",
    "    X, y, start_season=2010, window_size=None,\n",
    "    model_fn=rf_model_fn, model_params=best_params, verbose=True\n",
    ")\n",
    "\n",
    "# Train final model on all data from seasons >= start_season\n",
    "train_mask = X['Season'] >= 2011\n",
    "X_final = X[train_mask].drop(columns=['Season'])\n",
    "y_final = y[train_mask]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_final_scaled = scaler.fit_transform(X_final)\n",
    "\n",
    "# Train final model\n",
    "final_model = RandomForestClassifier(**best_params)\n",
    "final_model.fit(X_final_scaled, y_final)\n",
    "\n",
    "# Compute and visualize feature importances\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_final.columns,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 most important features:\")\n",
    "print(feature_importance.head(5))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "plt.title('Feature Importance (Final Random Forest Model)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Tournament Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T19:22:29.852120Z",
     "iopub.status.busy": "2025-05-03T19:22:29.851812Z",
     "iopub.status.idle": "2025-05-03T19:22:30.072160Z",
     "shell.execute_reply": "2025-05-03T19:22:30.070928Z",
     "shell.execute_reply.started": "2025-05-03T19:22:29.852095Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022: trained on 7532 rows ‚Üí 4556 preds  |  saved ‚Üí /home/benc/projects/ML-final/predictions/predictions_2022_rf.csv\n",
      "2023: trained on 7800 rows ‚Üí 4556 preds  |  saved ‚Üí /home/benc/projects/ML-final/predictions/predictions_2023_rf.csv\n",
      "2024: trained on 8068 rows ‚Üí 4556 preds  |  saved ‚Üí /home/benc/projects/ML-final/predictions/predictions_2024_rf.csv\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Set up output directory for predictions\n",
    "# ------------------------------------------------------------------\n",
    "if os.path.exists('/kaggle/input'):\n",
    "    preds_dir = Path('/kaggle/working/predictions')\n",
    "else:\n",
    "    project_root = Path(os.getcwd()).parent.parent\n",
    "    preds_dir = project_root / \"predictions\"\n",
    "\n",
    "# Make sure the directory exists\n",
    "preds_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Set model parameters from earlier optimization\n",
    "# ------------------------------------------------------------------\n",
    "rf_features = selected  # Final feature set (no \"Season\")\n",
    "base_params = best_params.copy()  # Best Optuna hyper-params\n",
    "window_size = best_window  # Best look-back window (may be None)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Generate predictions for each tournament season\n",
    "# ------------------------------------------------------------------\n",
    "for season in (2022, 2023, 2024):\n",
    "    # Train on the appropriate look-back window\n",
    "    if window_size is None:\n",
    "        train_mask = X[\"Season\"] < season\n",
    "    else:\n",
    "        train_mask = (X[\"Season\"] < season) & (X[\"Season\"] >= season - window_size - 1)\n",
    "\n",
    "    X_train_raw = X.loc[train_mask, rf_features]\n",
    "    y_train = y.loc[train_mask]\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler().fit(X_train_raw)\n",
    "    X_train = scaler.transform(X_train_raw)\n",
    "\n",
    "    # Train model\n",
    "    clf = RandomForestClassifier(**base_params).fit(X_train, y_train)\n",
    "\n",
    "    # Generate predictions for both men's and women's tournaments\n",
    "    all_dfs = []\n",
    "    for gender in (\"M\", \"W\"):\n",
    "        X_pred_raw, game_ids = generate_matchup_matrix(\"rf\", season, gender=gender)\n",
    "        X_pred_scaled = scaler.transform(X_pred_raw[rf_features])\n",
    "\n",
    "        y_hat = clf.predict_proba(X_pred_scaled)[:, 1]\n",
    "        all_dfs.append(pd.DataFrame({\n",
    "            \"Season\": season,\n",
    "            \"GameID\": game_ids,\n",
    "            \"y_hat_proba\": y_hat,\n",
    "        }))\n",
    "\n",
    "    # Save predictions to file\n",
    "    df_out = pd.concat(all_dfs, ignore_index=True)\n",
    "    out_f = preds_dir / f\"predictions_{season}_rf.csv\"\n",
    "    df_out.to_csv(out_f, index=False)\n",
    "\n",
    "    n_train = train_mask.sum()\n",
    "    print(f\"{season}: trained on {n_train:>4} rows ‚Üí {len(df_out):>4} preds  |  saved ‚Üí {out_f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8023814,
     "sourceId": 70068,
     "sourceType": "competition"
    },
    {
     "datasetId": 7013673,
     "sourceId": 11672619,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
